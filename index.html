<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Back Home AR</title>

  <script src="https://aframe.io/releases/1.6.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

  <style>
    html, body { margin:0; height:100%; overflow:hidden; background:transparent; }
  </style>

  <script>
    AFRAME.registerShader('video-matte', {
      schema: {
        videoColor: { type: 'map', is: 'uniform' },
        videoAlpha: { type: 'map', is: 'uniform' },
        opacity:    { type: 'number', default: 1.0, is: 'uniform' }
      },
      vertexShader: `varying vec2 vUV; void main(){ vUV=uv; gl_Position=projectionMatrix*modelViewMatrix*vec4(position,1.0); }`,
      fragmentShader: `
        precision highp float; varying vec2 vUV;
        uniform sampler2D videoColor, videoAlpha; uniform float opacity;
        void main(){
          vec4 c = texture2D(videoColor, vUV);
          float a = texture2D(videoAlpha, vUV).r;
          a = smoothstep(0.15, 0.95, a) * opacity;
          gl_FragColor = vec4(c.rgb, a);
        }
      `
    });
  </script>
</head>

<body>
  <a-scene
    mindar-image="imageTargetSrc: https://raw.githack.com/alevalve/AR_Crab_Backhome/main/targets.mind; autoStart: true"
    color-space="sRGB"
    renderer="colorManagement: true; physicallyCorrectLights: true"
    vr-mode-ui="enabled: false"
    device-orientation-permission-ui="enabled: true"
    embedded
  >
    <a-assets>
      <!-- Your videos (muted so page can auto-start; will unmute on targetFound) -->
      <video id="videoColor"
             src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Color.mp4"
             loop muted playsinline webkit-playsinline crossorigin="anonymous"></video>
      <video id="videoAlpha"
             src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Alpha.mp4"
             loop muted playsinline webkit-playsinline crossorigin="anonymous"></video>
    </a-assets>

    <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

    <!-- Simple target, like the website demo (index 0) -->
    <a-entity id="marker" mindar-image-target="targetIndex: 0">
      <!-- Show your composited video only when tracked -->
      <a-plane id="videoPlane"
        width="1.0" height="0.55"
        rotation="0 0 0" position="0 0 0"
        visible="false"
        material="shader: video-matte; videoColor: #videoColor; videoAlpha: #videoAlpha; transparent: true; depthWrite: false">
      </a-plane>
    </a-entity>
  </a-scene>

  <script>
    const marker = document.getElementById('marker');
    const plane  = document.getElementById('videoPlane');
    const vc     = document.getElementById('videoColor');
    const va     = document.getElementById('videoAlpha');

    vc.pause(); va.pause(); vc.muted = true;

    // Only play/unmute when the marker is actually tracked
    marker.addEventListener('targetFound', async () => {
      plane.setAttribute('visible', true);
      vc.muted = false;
      try { await vc.play(); } catch {}
      try { await va.play(); } catch {}
    });

    marker.addEventListener('targetLost', () => {
      plane.setAttribute('visible', false);
      vc.pause(); va.pause();
      vc.muted = true;
      vc.currentTime = 0; va.currentTime = 0;
    });
  </script>
</body>
</html>
